To accomplish the task of Image Captioning we will see how to implement a specific type of Attention mechanism called Bahdanauâ€™s Attention or Local Attention.  
I have used the Flickr8k dataset in which each image is associated with five different captions that describe the entities and events depicted in the image that were collected.  
In this article, multiple images are equivalent to multiple source language sentences in the translation. The advantage of BLEU is that the granularity it considers is an n-gram rather than a word, considering longer matching information.  
Link to the Article :- [A Hands-on Tutorial to Learn Attention Mechanism For Image Caption Generation in Python](https://www.analyticsvidhya.com/blog/2020/11/attention-mechanism-for-caption-generation/)
